import google.generativeai as genai
from typing import Dict, Any, Optional, Tuple, NamedTuple
import logging
import os
import base64
import requests
import time
from dotenv import load_dotenv

class GenerationResult(NamedTuple):
    """Result of story and image prompt generation."""
    story: str
    image_prompt: str
    model_name: str
    input_tokens: int
    output_tokens: int

class ImageGenerationResult(NamedTuple):
    """Result of image generation."""
    image_data: str
    model_name: str
    prompt_used: str
    generation_time_ms: float

class LLMHandler:
    def __init__(self, config_loader):
        """Initialize the LLM handler.
        
        Args:
            config_loader: Instance of ConfigLoader for accessing configuration
        """
        self.config_loader = config_loader
        self.logger = logging.getLogger(__name__)
        self.model = None
        self.api_key = None
        self.current_model_name = None
        self._initialize_model()
        
    def _initialize_model(self) -> bool:
        """Initialize the Gemini model.
        
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            # Get API key from environment variable or prompt user
            load_dotenv()
            self.api_key = os.getenv("GOOGLE_GEMINI_API_KEY")
            print("Loaded Gemini API key:", self.api_key)
            if not self.api_key:
                self.logger.error("No API key provided")
                return False
                
            # Configure Gemini
            genai.configure(api_key=self.api_key)
            
            # Get model configuration
            self.current_model_name = self.config_loader.get_config('model_name', 'gemini-1.5-flash-latest')
            temperature = self.config_loader.get_config('llm.temperature', 0.7)
            top_p = self.config_loader.get_config('llm.top_p', 0.95)
            top_k = self.config_loader.get_config('llm.top_k', 40)
            max_output_tokens = self.config_loader.get_config('max_output_tokens', 2500)
            
            # Initialize model with safety settings
            self.model = genai.GenerativeModel(
                self.current_model_name,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    max_output_tokens=max_output_tokens
                ),
                safety_settings=[
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": self.config_loader.get_config('safety.harassment_threshold', "BLOCK_MEDIUM_AND_ABOVE")
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH",
                        "threshold": self.config_loader.get_config('safety.hate_speech_threshold', "BLOCK_MEDIUM_AND_ABOVE")
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": self.config_loader.get_config('safety.sexually_explicit_threshold', "BLOCK_MEDIUM_AND_ABOVE")
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": self.config_loader.get_config('safety.dangerous_content_threshold', "BLOCK_MEDIUM_AND_ABOVE")
                    }
                ]
            )
            return True
            
        except Exception as e:
            self.logger.error(f"Error initializing Gemini model: {e}")
            return False
            
    def generate_story_and_image_prompt(
        self,
        user_story_prompt: str,
        persona_context: str,
        image_prompt_guidelines: str,
        character_name: str
    ) -> GenerationResult:
        """Generate a story and image prompt using the Gemini model.
        
        Args:
            user_story_prompt (str): User's story idea
            persona_context (str): Relevant persona context
            image_prompt_guidelines (str): Guidelines for image prompt generation
            character_name (str): Name of the character being used
            
        Returns:
            GenerationResult: Named tuple with story, image_prompt, model_name, and token counts
        """
        if not self.model:
            return GenerationResult(
                story="Error: Model not initialized", 
                image_prompt="Error: Model not initialized",
                model_name=self.current_model_name or "unknown",
                input_tokens=0,
                output_tokens=0
            )
            
        try:
            prompt = f"""**‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶≠‡ßÇ‡¶Æ‡¶ø‡¶ï‡¶æ (Your Role):**
‡¶Ü‡¶™‡¶®‡¶ø "{character_name}" ‡¶è‡¶∞ ‡¶™‡¶æ‡¶∞‡¶∏‡ßã‡¶®‡¶æ ‡¶ß‡¶æ‡¶∞‡¶£‡¶ï‡¶æ‡¶∞‡ßÄ ‡¶è‡¶ï‡¶ú‡¶® ‡¶Ö‡¶§‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶≠‡¶æ‡¶¨‡¶æ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßÉ‡¶ú‡¶®‡¶∂‡ßÄ‡¶≤ ‡¶ó‡¶≤‡ßç‡¶™‡¶ï‡¶æ‡¶∞‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶≤‡ßá‡¶ñ‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶∂‡¶¨‡ßç‡¶¶‡ßá ‡¶Ø‡ßá‡¶® {character_name} ‡¶è‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶≤‡¶ø‡¶™‡ßç‡¶§‡¶§‡¶æ, ‡¶™‡¶∞‡ßç‡¶Ø‡¶¨‡ßá‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡ßç‡¶∑‡¶Æ‡¶§‡¶æ, ‡¶ï‡ßå‡¶§‡ßÅ‡¶ï‡¶¨‡ßã‡¶ß ‡¶è‡¶¨‡¶Ç ‡¶¶‡¶æ‡¶∞‡ßç‡¶∂‡¶®‡¶ø‡¶ï ‡¶¶‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø‡¶≠‡¶ô‡ßç‡¶ó‡¶ø ‡¶´‡ßÅ‡¶ü‡ßá ‡¶ì‡¶†‡ßá‡•§

**‡¶ï‡¶†‡ßã‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶æ‡¶¨‡¶≤‡ßÄ (Strict Instructions):**

1.  **‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶Æ‡ßÇ‡¶≤ ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞‡¶¨‡¶ø‡¶®‡ßç‡¶¶‡ßÅ (Core Focus of the Story):** ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶ß‡¶æ‡¶® ‡¶â‡¶™‡¶ú‡ßÄ‡¶¨‡ßç‡¶Ø ‡¶π‡¶¨‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡¶æ‡¶∞‡ßÄ‡¶∞ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ "‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶Æ‡ßÇ‡¶≤ ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ" (User's Story Idea)‡•§ ‡¶è‡¶á ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ‡¶ï‡ßá ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞ ‡¶ï‡¶∞‡ßá‡¶á ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶§‡ßÅ‡¶® ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ó‡¶≤‡ßç‡¶™ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®‡•§
2.  **{character_name} ‡¶è‡¶∞ ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞‡¶æ‡¶Ø‡¶º‡¶£ ({character_name}'s Characterization):** ‡¶™‡ßç‡¶∞‡¶¶‡¶§‡ßç‡¶§ "‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶§‡¶•‡ßç‡¶Ø ({character_name} ‡¶è‡¶∞ ‡¶™‡¶æ‡¶∞‡¶∏‡ßã‡¶®‡¶æ)" ‡¶Ö‡¶Ç‡¶∂ ‡¶•‡ßá‡¶ï‡ßá {character_name} ‡¶è‡¶∞ ‡¶ö‡¶æ‡¶∞‡¶ø‡¶§‡ßç‡¶∞‡¶ø‡¶ï ‡¶¨‡ßà‡¶∂‡¶ø‡¶∑‡ßç‡¶ü‡ßç‡¶Ø, ‡¶Æ‡¶æ‡¶®‡¶∏‡¶ø‡¶ï ‡¶ó‡¶†‡¶®, ‡¶ú‡ßÄ‡¶¨‡¶®‡¶¶‡¶∞‡ßç‡¶∂‡¶®, ‡¶Ü‡¶ö‡¶∞‡¶£ ‡¶è‡¶¨‡¶Ç ‡¶¨‡¶æ‡¶ö‡¶®‡¶≠‡¶ô‡ßç‡¶ó‡¶ø ‡¶ó‡¶≠‡ßÄ‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶Ü‡¶§‡ßç‡¶Æ‡¶∏‡ßç‡¶• ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶ó‡¶≤‡ßç‡¶™‡ßá {character_name} ‡¶è‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ï‡¶•‡¶æ, ‡¶ï‡¶æ‡¶ú ‡¶è‡¶¨‡¶Ç ‡¶ö‡¶ø‡¶®‡ßç‡¶§‡¶æ ‡¶Ø‡ßá‡¶® ‡¶§‡¶æ‡¶∞ ‡¶™‡¶æ‡¶∞‡¶∏‡ßã‡¶®‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶∏‡¶ô‡ßç‡¶ó‡¶§‡¶ø‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶π‡¶Ø‡¶º‡•§
3.  **‡¶∏‡¶Ç‡¶≤‡¶æ‡¶™ ‡¶ì ‡¶¨‡¶∞‡ßç‡¶£‡¶®‡¶æ (Dialogue and Narrative):** ‡¶ó‡¶≤‡ßç‡¶™‡¶ü‡¶ø {character_name} ‡¶è‡¶∞ ‡¶®‡¶ø‡¶ú‡¶∏‡ßç‡¶¨ ‡¶ú‡¶¨‡¶æ‡¶®‡¶ø‡¶§‡ßá (first-person narrative) ‡¶Ö‡¶•‡¶¨‡¶æ ‡¶è‡¶Æ‡¶®‡¶≠‡¶æ‡¶¨‡ßá ‡¶≤‡¶ø‡¶ñ‡ßÅ‡¶® ‡¶Ø‡ßá‡¶® ‡¶™‡¶æ‡¶†‡¶ï {character_name} ‡¶è‡¶∞ ‡¶ö‡¶ø‡¶®‡ßç‡¶§‡¶æ‡¶∞ ‡¶ú‡¶ó‡¶§‡ßá‡¶∞ ‡¶Ö‡¶Ç‡¶∂ ‡¶π‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶Ø‡¶º‡•§
4.  **‡¶ï‡¶™‡¶ø ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ (Strictly No Copying):** "‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶§‡¶•‡ßç‡¶Ø ({character_name} ‡¶è‡¶∞ ‡¶™‡¶æ‡¶∞‡¶∏‡ßã‡¶®‡¶æ)" ‡¶¨‡¶æ "‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶§‡ßà‡¶∞‡¶ø‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶ø‡¶ï‡¶æ" ‡¶•‡ßá‡¶ï‡ßá ‡¶ï‡ßã‡¶®‡ßã ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø, ‡¶Ö‡¶®‡ßÅ‡¶ö‡ßç‡¶õ‡ßá‡¶¶ ‡¶¨‡¶æ ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶Ö‡¶Ç‡¶∂ ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡¶§‡ßÅ‡¶® ‡¶ó‡¶≤‡ßç‡¶™ ‡¶¨‡¶æ ‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü‡ßá **‡¶ï‡¶™‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶¨‡ßá ‡¶®‡¶æ**‡•§ ‡¶è‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ ‡¶ì ‡¶≠‡¶ô‡ßç‡¶ó‡¶ø ‡¶¨‡ßã‡¶ù‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶è‡¶ï‡¶ü‡¶ø **‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶Æ‡ßå‡¶≤‡¶ø‡¶ï ‡¶ì ‡¶®‡¶§‡ßÅ‡¶®** ‡¶ó‡¶≤‡ßç‡¶™ ‡¶è‡¶¨‡¶Ç ‡¶§‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø **‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶Æ‡ßå‡¶≤‡¶ø‡¶ï ‡¶ì ‡¶®‡¶§‡ßÅ‡¶®** ‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§
5.  **‡¶∏‡¶Æ‡¶®‡ßç‡¶¨‡¶Ø‡¶º (Integration):** ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡¶æ‡¶∞‡ßÄ‡¶∞ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ "‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶Æ‡ßÇ‡¶≤ ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ"‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá {character_name} ‡¶è‡¶∞ ‡¶™‡¶æ‡¶∞‡¶∏‡ßã‡¶®‡¶æ ‡¶ì ‡¶§‡¶æ‡¶∞ ‡¶ú‡¶ó‡ßé‡¶ï‡ßá ‡¶∏‡ßÉ‡¶ú‡¶®‡¶∂‡ßÄ‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶Æ‡¶®‡ßç‡¶¨‡¶Ø‡¶º ‡¶ò‡¶ü‡¶æ‡¶®‡•§
6.  **‡¶≠‡¶æ‡¶∑‡¶æ (Language):** ‡¶ó‡¶≤‡ßç‡¶™‡¶ü‡¶ø ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á ‡¶™‡ßç‡¶∞‡¶æ‡¶û‡ßç‡¶ú‡¶≤, ‡¶∏‡¶æ‡¶π‡¶ø‡¶§‡ßç‡¶Ø‡¶ø‡¶ï ‡¶Æ‡¶æ‡¶®‡¶∏‡¶Æ‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶≤‡¶ø‡¶ñ‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§
7.  **‡¶Ö‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï‡¶§‡¶æ ‡¶™‡¶∞‡¶ø‡¶π‡¶æ‡¶∞ (Avoid Irrelevance):** ‡¶Ø‡¶¶‡¶ø ‡¶ó‡¶≤‡ßç‡¶™ ‡¶§‡ßà‡¶∞‡¶ø‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶Ø‡¶•‡ßá‡¶∑‡ßç‡¶ü ‡¶â‡¶™‡¶æ‡¶¶‡¶æ‡¶® ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶¨‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§, {character_name} ‡¶∏‡ßÅ‡¶≤‡¶≠ ‡¶∞‡¶π‡¶∏‡ßç‡¶Ø‡¶Æ‡¶Ø‡¶º ‡¶Æ‡¶®‡ßç‡¶§‡¶¨‡ßç‡¶Ø ‡¶ï‡¶∞‡ßÅ‡¶®‡•§

---
**‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶§‡¶•‡ßç‡¶Ø ({character_name} ‡¶è‡¶∞ ‡¶™‡¶æ‡¶∞‡¶∏‡ßã‡¶®‡¶æ, ‡¶≤‡ßá‡¶ñ‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶ß‡¶∞‡¶£, ‡¶ü‡¶æ‡¶á‡¶Æ‡¶≤‡¶æ‡¶á‡¶® ‡¶á‡¶§‡ßç‡¶Ø‡¶æ‡¶¶‡¶ø):**
{persona_context}
---

**‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶§‡ßà‡¶∞‡¶ø‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶ø‡¶ï‡¶æ (Guidelines for Image Prompt Generation):**
{image_prompt_guidelines}
---

**‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶Æ‡ßÇ‡¶≤ ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ (User's Story Idea - ‡¶è‡¶á ‡¶Ö‡¶Ç‡¶∂‡¶ü‡¶ø‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶≠‡¶æ‡¶¨‡ßá ‡¶®‡¶ú‡¶∞ ‡¶¶‡¶ø‡¶® ‡¶è‡¶¨‡¶Ç ‡¶è‡¶ü‡¶ø‡¶ï‡ßá ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶§‡ßÅ‡¶® ‡¶è‡¶ï‡¶ü‡¶ø "{character_name}" ‡¶ó‡¶≤‡ßç‡¶™ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®):**
{user_story_prompt}
---

**‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶ú (Your Task):**

**‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶ß‡¶æ‡¶™:** ‡¶â‡¶™‡¶∞‡ßá‡¶∞ ‡¶ï‡¶†‡ßã‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶æ‡¶¨‡¶≤‡ßÄ ‡¶è‡¶¨‡¶Ç {character_name} ‡¶è‡¶∞ ‡¶™‡¶æ‡¶∞‡¶∏‡ßã‡¶®‡¶æ ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶∞‡¶£ ‡¶ï‡¶∞‡ßá, "‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶Æ‡ßÇ‡¶≤ ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ" ‡¶ü‡¶ø‡¶ï‡ßá ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶§‡ßÅ‡¶®, ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§, ‡¶∏‡ßÉ‡¶ú‡¶®‡¶∂‡ßÄ‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶æ‡¶π‡¶ø‡¶§‡ßç‡¶Ø‡¶Æ‡¶æ‡¶® ‡¶∏‡¶Æ‡ßÉ‡¶¶‡ßç‡¶ß ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶ó‡¶≤‡ßç‡¶™ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®‡•§

**‡¶¶‡ßç‡¶¨‡¶ø‡¶§‡ßÄ‡¶Ø‡¶º ‡¶ß‡¶æ‡¶™:** ‡¶ó‡¶≤‡ßç‡¶™‡¶ü‡¶ø ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶™‡¶∞, ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡¶¨‡¶∏‡ßç‡¶§‡ßÅ, ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞, ‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂, ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶¨‡ßá‡¶ó‡ßá‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø ‡¶ï‡¶∞‡ßá, ‡¶™‡ßç‡¶∞‡¶¶‡¶§‡ßç‡¶§ "‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶§‡ßà‡¶∞‡¶ø‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶ø‡¶ï‡¶æ" ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶∞‡¶£ ‡¶ï‡¶∞‡ßá, ‡¶∏‡ßá‡¶á ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø **‡¶Ö‡¶§‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßÉ‡¶ú‡¶®‡¶∂‡ßÄ‡¶≤ "‡¶á‡¶Æ‡ßá‡¶ú ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü"** ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶è‡¶á ‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü‡¶ü‡¶ø ‡¶è‡¶Æ‡¶®‡¶≠‡¶æ‡¶¨‡ßá ‡¶≤‡¶ø‡¶ñ‡ßÅ‡¶® ‡¶Ø‡ßá‡¶® ‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶≠‡¶ø‡¶ú‡ßç‡¶Ø‡ßÅ‡¶Ø‡¶º‡¶æ‡¶≤ ‡¶Ü‡¶∞‡ßç‡¶ü‡¶ø‡¶∏‡ßç‡¶ü‡¶ï‡ßá (‡¶è‡¶Ü‡¶á) ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶Æ‡ßÇ‡¶≤ ‡¶¶‡ßÉ‡¶∂‡ßç‡¶Ø‡¶™‡¶ü ‡¶´‡ßÅ‡¶ü‡¶ø‡¶Ø‡¶º‡ßá ‡¶§‡ßÅ‡¶≤‡¶§‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡ßá‡•§ ‡¶è‡¶á ‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü‡¶ü‡¶ø ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á "‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶á‡¶Æ‡ßá‡¶ú ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü (‡¶Ö‡¶§‡¶ø ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§):" ‡¶è‡¶á ‡¶∂‡¶ø‡¶∞‡ßã‡¶®‡¶æ‡¶Æ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá ‡¶è‡¶¨‡¶Ç ‡¶è‡¶ü‡¶ø ‡¶π‡¶¨‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞‡ßá‡¶∞ **‡¶∂‡ßá‡¶∑ ‡¶Ö‡¶Ç‡¶∂**‡•§

‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶ó‡¶≤‡ßç‡¶™ ‡¶è‡¶¨‡¶Ç ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ ‡¶á‡¶Æ‡ßá‡¶ú ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü‡¶ü‡¶ø ‡¶®‡¶ø‡¶ö‡ßá ‡¶¶‡¶ø‡¶®‡•§
"""
            
            response = self.model.generate_content(prompt)
            
            if not response.parts:
                return GenerationResult(
                    story="Error: No response from model", 
                    image_prompt="Error: No response from model",
                    model_name=self.current_model_name or "unknown",
                    input_tokens=0,
                    output_tokens=0
                )
                
            generated_text = response.text
            
            # Extract token usage information
            input_tokens = 0
            output_tokens = 0
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                input_tokens = getattr(response.usage_metadata, 'prompt_token_count', 0)
                output_tokens = getattr(response.usage_metadata, 'candidates_token_count', 0)
            
            story_part = ""
            image_prompt_part = ""
            
            # Split the response into story and image prompt
            image_prompt_marker = "‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶á‡¶Æ‡ßá‡¶ú ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü (‡¶Ö‡¶§‡¶ø ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§):"
            if image_prompt_marker in generated_text:
                parts = generated_text.split(image_prompt_marker, 1)
                story_part = parts[0].strip()
                if len(parts) > 1:
                    image_prompt_part = parts[1].strip()
            else:
                story_part = generated_text.strip()
                image_prompt_part = "Error: Could not find image prompt section"
                
            return GenerationResult(
                story=story_part,
                image_prompt=image_prompt_part,
                model_name=self.current_model_name or "unknown",
                input_tokens=input_tokens,
                output_tokens=output_tokens
            )
            
        except Exception as e:
            error_msg = f"Error generating content: {str(e)}"
            self.logger.error(error_msg)
            return GenerationResult(
                story=error_msg, 
                image_prompt=error_msg,
                model_name=self.current_model_name or "unknown",
                input_tokens=0,
                output_tokens=0
            ) 

    def reinitialize_with_new_api_key(self) -> bool:
        """Reinitialize the LLM handler with a new API key from environment.
        
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            # Reload environment variables to get updated API key
            load_dotenv(override=True)  # override=True forces reload
            new_api_key = os.getenv("GOOGLE_GEMINI_API_KEY")
            
            if not new_api_key:
                self.logger.error("No API key found in environment")
                return False
                
            if new_api_key == self.api_key:
                self.logger.info("API key unchanged, no reinitalization needed")
                return True
                
            self.logger.info("Reinitializing LLM handler with new API key")
            self.api_key = new_api_key
            
            # Reconfigure Gemini with new API key
            genai.configure(api_key=self.api_key)
            
            # Reinitialize model (this will use the new API key)
            model_name = self.config_loader.get_config('model_name', 'gemini-1.5-flash-latest')
            temperature = self.config_loader.get_config('llm.temperature', 0.7)
            top_p = self.config_loader.get_config('llm.top_p', 0.95)
            top_k = self.config_loader.get_config('llm.top_k', 40)
            max_output_tokens = self.config_loader.get_config('max_output_tokens', 2500)
            
            self.current_model_name = model_name
            self.model = genai.GenerativeModel(
                model_name,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    max_output_tokens=max_output_tokens
                ),
                safety_settings=[
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": self.config_loader.get_config('safety.harassment_threshold', "BLOCK_MEDIUM_AND_ABOVE")
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH",
                        "threshold": self.config_loader.get_config('safety.hate_speech_threshold', "BLOCK_MEDIUM_AND_ABOVE")
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": self.config_loader.get_config('safety.sexually_explicit_threshold', "BLOCK_MEDIUM_AND_ABOVE")
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": self.config_loader.get_config('safety.dangerous_content_threshold', "BLOCK_MEDIUM_AND_ABOVE")
                    }
                ]
            )
            
            self.logger.info("LLM handler successfully reinitialized with new API key")
            return True
            
        except Exception as e:
            self.logger.error(f"Error reinitializing LLM handler: {e}")
            return False

    def generate_image(self, prompt: str, quality: str = "high", size: str = "1024x1024") -> ImageGenerationResult:
        """Generate an image using Pollinations.ai with Flux.1-dev model.
        
        Args:
            prompt (str): The image generation prompt
            quality (str): Quality setting (standard, high, ultra)
            size (str): Image size (512x512, 1024x1024, 1024x1792)
            
        Returns:
            ImageGenerationResult: Named tuple with image data and metadata
        """
        start_time = time.time()
        
        try:
            # Enhanced prompt processing for better quality with Flux.1-dev
            enhanced_prompt = self._enhance_flux_prompt(prompt, quality)
            self.logger.info(f"Generating image with Pollinations.ai Flux.1-dev: {enhanced_prompt[:100]}...")
            self.logger.info(f"Settings: quality={quality}, size={size}")
            
            # Try Pollinations.ai with Flux.1-dev model
            image_data = self._generate_with_pollinations_flux(enhanced_prompt, quality, size)
            
            if image_data:
                generation_time = (time.time() - start_time) * 1000
                self.logger.info(f"Successfully generated image using Pollinations.ai Flux.1-dev")
                
                return ImageGenerationResult(
                    image_data=image_data,
                    model_name="pollinations-flux-1-dev",
                    prompt_used=enhanced_prompt,
                    generation_time_ms=generation_time
                )
            
            # Fallback to enhanced placeholder if service fails
            return self._generate_enhanced_placeholder(prompt, quality, size, start_time)
            
        except Exception as e:
            self.logger.error(f"Image generation failed: {str(e)}")
            return self._generate_enhanced_placeholder(prompt, quality, size, start_time)

    def _enhance_flux_prompt(self, prompt: str, quality: str) -> str:
        """Enhance prompts specifically for Flux.1-dev model for better results."""
        
        # Quality-specific enhancements for Flux.1-dev
        quality_terms = {
            "standard": "detailed, clear, well-composed",
            "high": "high quality, detailed, professional, sharp focus, 8k resolution",
            "ultra": "masterpiece, ultra high quality, extremely detailed, professional photography, 8k resolution, award-winning, cinematic masterpiece, hyperrealistic, perfect composition"
        }
        
        # Flux.1-dev specific style enhancements based on quality
        if quality == "ultra":
            flux_enhancers = [
                "photorealistic",
                "cinematic lighting", 
                "detailed textures",
                "vibrant colors",
                "sharp focus",
                "professional composition",
                "studio lighting",
                "perfect exposure",
                "highly detailed"
            ]
        elif quality == "high":
            flux_enhancers = [
                "photorealistic",
                "cinematic lighting", 
                "detailed textures",
                "vibrant colors",
                "sharp focus",
                "professional composition"
            ]
        else:
            flux_enhancers = [
                "photorealistic",
                "good lighting", 
                "detailed",
                "clear focus"
            ]
        
        # Build enhanced prompt
        enhanced = f"{quality_terms.get(quality, quality_terms['high'])}, "
        
        # Add more enhancers for ultra quality
        if quality == "ultra":
            enhanced += f"{', '.join(flux_enhancers[:6])}, "
        else:
            enhanced += f"{', '.join(flux_enhancers[:3])}, "
            
        enhanced += prompt
        
        # Add quality-specific endings
        if quality == "ultra":
            enhanced += ", highly detailed, best quality, professional grade, museum quality"
        elif quality == "high":
            enhanced += ", highly detailed, best quality"
        else:
            enhanced += ", detailed, good quality"
        
        return enhanced

    def _generate_with_pollinations_flux(self, prompt: str, quality: str, size: str) -> Optional[str]:
        """Generate image using Pollinations.ai with Flux.1-dev model."""
        try:
            # Pollinations.ai API with Flux.1-dev model
            # Parse size for API
            width, height = size.split('x')
            
            # Pollinations.ai endpoint with Flux.1-dev
            url = "https://image.pollinations.ai/prompt/"
            
            # URL encode the prompt and add Flux.1-dev specific parameters
            import urllib.parse
            encoded_prompt = urllib.parse.quote(prompt)
            
            # Construct the full URL with Flux.1-dev parameters
            full_url = f"{url}{encoded_prompt}?model=flux&width={width}&height={height}&enhance=true"
            
            # Add quality-specific parameters
            if quality == "ultra":
                full_url += "&steps=50&cfg=7.5"
            elif quality == "high": 
                full_url += "&steps=30&cfg=7.0"
            else:
                full_url += "&steps=20&cfg=6.5"
            
            self.logger.info(f"Calling Pollinations.ai Flux.1-dev API: {full_url[:150]}...")
            
            # Make request with timeout
            response = requests.get(full_url, timeout=60)
            
            if response.status_code == 200:
                # Convert image to base64
                image_data = base64.b64encode(response.content).decode('utf-8')
                self.logger.info(f"Pollinations.ai Flux.1-dev response: {len(image_data)} characters")
                return image_data
            else:
                self.logger.error(f"Pollinations.ai Flux.1-dev API error: {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"Pollinations.ai Flux.1-dev generation failed: {str(e)}")
            return None

    def _generate_enhanced_placeholder(self, prompt: str, quality: str, size: str, start_time: float) -> ImageGenerationResult:
        """Generate an enhanced placeholder with AI-generated description when real generation fails."""
        try:
            # Use Gemini to generate a detailed visual description
            description_prompt = f"Create a detailed, vivid description of this image concept: {prompt}. Describe colors, lighting, composition, mood, and visual details in 2-3 sentences."
            
            if self.model:
                response = self.model.generate_content(description_prompt)
                ai_description = response.text.strip()
            else:
                ai_description = f"A detailed visualization of: {prompt}"
            
            # Create enhanced placeholder image data (SVG with gradient and details)
            width, height = size.split('x')
            
            # Generate a beautiful gradient placeholder with AI description
            placeholder_svg = f'''<svg width="{width}" height="{height}" xmlns="http://www.w3.org/2000/svg">
                <defs>
                    <linearGradient id="grad" x1="0%" y1="0%" x2="100%" y2="100%">
                        <stop offset="0%" style="stop-color:#667eea;stop-opacity:1" />
                        <stop offset="100%" style="stop-color:#764ba2;stop-opacity:1" />
                    </linearGradient>
                </defs>
                <rect width="100%" height="100%" fill="url(#grad)"/>
                <text x="50%" y="40%" text-anchor="middle" fill="white" font-family="Arial" font-size="24" font-weight="bold">üé® Flux.1-dev Image</text>
                <text x="50%" y="55%" text-anchor="middle" fill="white" font-family="Arial" font-size="16">Generated with AI Enhancement</text>
                <text x="50%" y="75%" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-family="Arial" font-size="12">Powered by Pollinations.ai</text>
            </svg>'''
            
            # Convert SVG to base64
            placeholder_data = base64.b64encode(placeholder_svg.encode('utf-8')).decode('utf-8')
            
            generation_time = (time.time() - start_time) * 1000
            
            return ImageGenerationResult(
                image_data=placeholder_data,
                model_name="pollinations-flux-1-dev-enhanced-placeholder", 
                prompt_used=f"Enhanced: {ai_description}",
                generation_time_ms=generation_time
            )
            
        except Exception as e:
            self.logger.error(f"Enhanced placeholder generation failed: {str(e)}")
            # Simple fallback
            generation_time = (time.time() - start_time) * 1000
            simple_placeholder = base64.b64encode(b'<svg width="1024" height="1024" xmlns="http://www.w3.org/2000/svg"><rect width="100%" height="100%" fill="#667eea"/><text x="50%" y="50%" text-anchor="middle" fill="white" font-size="20">Flux.1-dev Image</text></svg>').decode('utf-8')
            
            return ImageGenerationResult(
                image_data=simple_placeholder,
                model_name="pollinations-flux-1-dev-fallback",
                prompt_used=prompt,
                generation_time_ms=generation_time
            )

    def _generate_with_pollinations_enhanced(self, prompt: str, size: str, quality: str) -> tuple[str, str]:
        """Disabled - not using Pollinations.ai anymore."""
        return None, None

    def _generate_with_leonardo(self, prompt: str, size: str, quality: str) -> tuple[str, str]:
        """Disabled - not using Leonardo.ai anymore.""" 
        return None, None

    def _generate_with_huggingface_enhanced(self, prompt: str, size: str, quality: str) -> tuple[str, str]:
        """Disabled - not using Hugging Face anymore."""
        return None, None

    def _generate_with_stability_ai(self, prompt: str, size: str, quality: str) -> tuple[str, str]:
        """Disabled - not using Stability AI anymore."""
        return None, None

    def _generate_placeholder_image(self, prompt: str, size: str) -> tuple[str, str]:
        """Generate an enhanced placeholder image with text."""
        try:
            from PIL import Image, ImageDraw, ImageFont
            import io
            
            # Parse size
            width, height = map(int, size.split('x')) if 'x' in size else (1024, 1024)
            
            # Create image
            img = Image.new('RGB', (width, height), color='#f0f0f0')
            draw = ImageDraw.Draw(img)
            
            # Try to use a font, fallback to default
            try:
                font_size = min(width, height) // 20
                font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", font_size)
            except:
                font = ImageFont.load_default()
            
            # Add text
            text_lines = [
                "üé® AI Image Generation",
                "",
                f"Prompt: {prompt[:50]}{'...' if len(prompt) > 50 else ''}",
                "",
                f"Size: {size}",
                "",
                "‚ö†Ô∏è Using placeholder",
                "Configure API keys for real generation"
            ]
            
            # Calculate text positioning
            y_offset = height // 4
            line_height = font_size + 10 if hasattr(font, 'size') else 20
            
            for line in text_lines:
                if line:  # Skip empty lines
                    bbox = draw.textbbox((0, 0), line, font=font)
                    text_width = bbox[2] - bbox[0]
                    x = (width - text_width) // 2
                    draw.text((x, y_offset), line, fill='#666666', font=font)
                y_offset += line_height
            
            # Add border
            draw.rectangle([0, 0, width-1, height-1], outline='#cccccc', width=2)
            
            # Convert to base64
            buffer = io.BytesIO()
            img.save(buffer, format='PNG')
            image_data = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return image_data, "enhanced-placeholder"
            
        except Exception as e:
            self.logger.warning(f"Enhanced placeholder generation failed: {e}")
            # Fallback to simple placeholder
            simple_placeholder = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg=="
            return simple_placeholder, "simple-placeholder" 